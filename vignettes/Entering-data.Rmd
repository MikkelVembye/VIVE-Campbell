---
title: "Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe"
author: "Mikkel H. Vembye"
date: "Last modified `r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    number_sections: true
    toc: true
bibliography: bibliography.bib
biblio-style: apa
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{dplyr}
  %\VignetteDepends{tibble}
  %\VignetteDepends{purrr}
  %\VignetteDepends{tidyr}
  %\VignetteDepends{ggplot2}
  %\VignetteDepends{gt}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE, }
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

options(pillar.sigfig = 4) # ensure tibble include 4 digits
options(tibble.width = Inf)
options(dplyr.print_min = 310)
options(scipen = 10)
options(dplyr.summarise.inform = FALSE)
```

# Introduktion

<div class="warning" style='margin-left:2em; margin-right:2em; margin-bottom:2em; margin-top:2em; padding:0.1em; background-color: #d7dbdd; border: solid #bdc3c7 3px'>
<span>
<p style='margin-top:1em; text-align:center'>
<b>Vigtig note</b></p>
<p style='margin:1em'>
Hvis du endnu ikke har arbejdet med R, så har [Jens](https://www.vive.dk/da/medarbejdere/jens-dietrichson-06zk186j/) og jeg skrevet den lille blog ["Kom godt i gang med metaanalyse i R"](https://mikkelvembye.github.io/VIVECampbell/articles/meta-analysis-in-R.html), som jeg vil anbefale at gennemse sammen med denne blog. Alternativ kan de også være en god ide at læse det første kapitel i [R4DS](https://r4ds.had.co.nz/). Nedenfor loader jeg en række af de pakker som vi ofteste benytter i forbindelse med dataindtastning og effektstørrelsesudregning. Dog vil jeg fremhæve, at den langt vigtigste af disse pakker er [`dplyr`](https://dplyr.tidyverse.org/). Det kan være en ret stor fordel at blive god til grundfunktionerne i denne pakke, dvs. `filter()`, `mutate()`, `group_by()`, `summarise()`, `arrange()` og `select()`.
</p></span>
</div>

<br />

Denne vignette/blog er tiltænkt at skulle være en basic introduktion til en række vigtige emner, som er relevante, når man skal indtaste komplex resultatdata og beregne effektstørrelser fra studier, som skal med i vores systematiske reviews. En vigtig del af vignetten handler om at vise, hvordan man benytter funktionerne `vgt_smd_1armcluster()`, `df_h_1armcluster()`, `eta_1armcluster()` og `gamma_1armcluster()` fra `VIVECampbell` R pakken. Vignetten er opbygget som følger: I første del gennemgår jeg, hvordan kompleks data indtastes, og jeg taler kort om, hvilket fejl man typisk laver, når man indtaster data. Derefter viser jeg tre af de mest normale/typiske effektstørrelser, som man støder på i socialvidenskaben. Herefter viser jeg, hvordan disse kan beregnes. Jeg viser blandt andet, hvordan man ofte kan beregne pre-posttest korrelationer mellem outcomes, når vise datastrukturer afrapporteres i primær forskningen. I den sidste del, viser jeg, hvordan vi kan kluster bias korrigere vores effekter, når der kun er klustering i en gruppe samt hvordan man kan estimere varians-covarians matricer for studier med flere treatment (og/eller kontrol) grupper. Her viser jeg hvordan man kan benytte `vcalc()` funktionen fra `metafor`-pakken. Afsluttende viser jeg, hvordan man kan visualisere den konstruerede effektstørrelsesdata.     


## Nødvendige pakker og hjælpsomme options

Når du er klar til at gå ombord i denne blog, kan du nedenfor se, de pakker som bloggen trækker på. Ud fra hver pakke har jeg beskrevet, hvad pakkens eller optionens primære rolle er. For at hente `VIVECampbell` skal i fjerne # foran hhv. `install.packages("devtools")` og `devtools::install_github("MikkelVembye/VIVECampbell")` og så køre disse koder. Dette skal kun gøre første gang man kører koderne. Dog ikke nødvendigt at gøre, hvis man allerede har hentet `VIVECampbell`-pakken.


```{r setup, message=FALSE, warning=FALSE}
#install.packages("devtools")
#devtools::install_github("MikkelVembye/VIVECampbell")

library(VIVECampbell) # Indholder funktioner til at udføre cluster bias justeringer
library(purrr) # Indeholde vigtige loop (map) funktioner, der gør det let at gentage mange ens udregninger og dataændringer
library(dplyr) # Nøglepakke til at manipulere data
library(tidyr) # Indeholder vigtige pivot_ funktioner, som hjælper med at ændre dataset fra wide til long format vice versa
library(gt)    # Tabelkonstruktionens svar på ggplot2
library(ggplot2) # Til at visualisere plot
library(tibble) # En type af data.frames som er mere effektive. I vil se, at jeg altid arbejder med tibbler og ikke rå data.frames
library(metafor) # benytte vi til at beregne variance-covariance matrix

# Options som jeg for det mest benytter
options(pillar.sigfig = 4) # Resultater printes med 4 decimaler
options(tibble.width = Inf) # Sikre at alle variabler printes
options(dplyr.print_min = 310) # Antal rækker som printes fra et datasæt
options(scipen = 10) # Indikerer hvormange decimaler der skal være før R printer videnskabelige numre
options(dplyr.summarise.inform = FALSE) # Undgår info fra summarize() fra dplyr

```

# Kompleks resultdata og hvordan den kan indtastes (long-format)

Når vi laver systematiske reviews, støder vi meget tit på studier, som afrapporterer rigtig mange resultater, som er relevante for vores review. Et typisk eksempel kan se ud som Tabel 1 nedenfor fra Fisher & Bentley [-@Fisher1996].^[Det vigtigt here at sige her, at Tabel 1 kunne bruges som et fiktivt eksempel, så man kan ikke drage nogen substantielle fortolkninger af denne blog. Tabel 1 er udelukkende konstrueret for eksempels skyld.]


```{r, echo=FALSE}
tibble::tibble(
  
  outcome = rep(c("Alcohol use", "Drug use", "Social and family relations", "Psychological functioning"), each = 3),
  groups = rep(c("Disease-and-recovery group", "Cognitive-behavioral group", 
                 "Usual individual treatment"), 4),
  Pretest_m = c(".469", ".441", ".349", ".107", ".116", ".117", ".342", ".419", ".450", ".393", ".498", ".605"),
  Pretest_sd = c(".12", ".13", ".22", ".09", ".10", ".12", ".21", ".12", ".24", ".17", ".13", ".15"),
  Posttest_m = c(".070", ".018", ".141", ".001", ".008", ".087", ".083", ".103", ".489", ".319", ".442", ".601"),
  Posttest_sd = c(".11", ".05", ".21", ".01", ".02", ".12", ".10", ".10", ".18", ".14", ".16", ".18"),
  Diff_m = c(".399", ".423", ".208", ".106", ".108", ".030", ".259", ".316", "-.039", ".074", ".056", ".004"),
  Diff_sd = c(".02", ".09", ".04", ".09", ".09", ".02", ".13", ".03", ".07", ".04", ".04", ".04"),
  Pretest_m2 = c(".725", ".598", ".682", ".219", ".200", ".322", ".683", ".584", ".571", ".464", ".476", ".487"),
  Pretest_sd2 = c(".11", ".16", ".17", ".11", ".12", ".05", ".04", ".05", ".09", ".14", ".12", ".16"),
  Posttest_m2 = c(".521", ".152", ".492", ".167", ".044", ".216", ".641", ".233", ".514", ".432", ".232", ".472"),
  Posttest_sd2 = c(".11", ".15", ".27", ".10", ".05", ".15", ".06", ".16", ".12", ".18", ".07", ".18"),
  Diff_m2 = c(".204", ".446", ".190", ".052", ".196", ".106", ".042", ".351", ".057", ".032", ".244", ".015"),
  Diff_sd2 = c(".01", ".02", ".11", ".02", ".08", ".11", ".03", ".12", ".04", ".05", ".06", ".03"),
  
) |> 
gt(rowname_col = "groups", groupname_col = "outcome") |> 
  tab_header(
    title = md("**Tabel 1**"),
    subtitle = md("*Reproduceret med inspiration fra Tabel 4 i Fisher (1996, p. 1248)*")
  ) |> 
  opt_align_table_header(align = "left") |> 
  tab_spanner(
    label = html("Pretest<br>score"),
    columns = c(Pretest_m:Pretest_sd)
  ) |> 
  tab_spanner(
    label = html("Posttest<br>score"),
    columns = c(Posttest_m:Posttest_sd)
  ) |> 
  tab_spanner(
    label = html("<br>Difference"),
    columns = c(Diff_m:Diff_sd)
  ) |> 
  tab_spanner(
    label = "Inpatient setting",
    columns = c(Pretest_m:Diff_sd)
  ) |> 
  tab_spanner(
    label = html("Pretest<br>score", id = ""),
    columns = c(Pretest_m2:Pretest_sd2)
  ) |> 
  tab_spanner(
    label = html("Posttest<br>score", id = ""),
    columns = c(Posttest_m2:Posttest_sd2)
  ) |> 
  tab_spanner(
    label = html("<br>Difference", id = ""),
    columns = c(Diff_m2:Diff_sd2)
  ) |> 
  tab_spanner(
    label = "Outpatient setting",
    columns = c(Pretest_m2:Diff_sd2)
  ) |> 
  cols_label(
    Pretest_m = "Mean",
    Pretest_sd = "SD",
    Posttest_m = "Mean",
    Posttest_sd = "SD",
    Diff_m = "Mean",
    Diff_sd = "SD",
    Pretest_m2 = "Mean",
    Pretest_sd2 = "SD",
    Posttest_m2 = "Mean",
    Posttest_sd2 = "SD",
    Diff_m2 = "Mean",
    Diff_sd2 = "SD",
  ) |> 
  tab_stubhead(label = md("Subscale and<br>therapy group")) 

```

Som det kan ses her, er den resultatsdata som skal udtrækkes relativ kompleks med pretest, posttest og difference mål nested inden for treatment grupper (dvs. Disease-and-recovery, Coginitive behavioral og TAU grupperne), som er nestet inden for kontekster/settings (dvs. Inpatient og Outpatient settings), som igen er nestet inden for outcomes (dvs. Alcohol use, Drug use, Social and family relations samt Psychological functioning). Jeg vil senere vise, hvordan man kan arbejde med effektstørrelsesdata, hvor man har mere end en treatment- eller kontrolgruppe. Men først lidt introduktion til en vigtig basic funktion. Når man vil konstruere et datasæt i R er en vigtig `base::`-funktion at kende til den som hedder `rep()`. Den tillader at replikere de samme værdier på forskellig vis inden for en given variabel. Nedenfor at vise en række eksempler på, hvordan denne kan bruges. 
```{r rep-function}
# Her replikeres den samme værdirækkefølge x (dvs. i dette tilfæde 4) gange
rep(LETTERS[1:3], 4)

# Her replikeres hver værdi x (dvs. i dette tilfæde 3) gange
rep(LETTERS[1:3], each = 3)

# Ovenstående operationer kan også kombineres
rep(LETTERS[1:3], each = 2, 2)

# Man kan også skabe en variable med en fast antal gentagelser således
rep(LETTERS[1:3], length.out = 11)

# Igen alle disse operationer kan kombineres i samme funktion
rep(LETTERS[1:3], each = 2, 2, length.out = 11)
```

Nedenfor viser jeg, hvordan man kunne indtaste data fra Tabel 1 vha. `tibble()` samt `rep()`. Måden, hvorpå jeg indtaster data kaldes af nogen for long format data, hvor hver treatment gruppernes (dvs.  Disease-and-recovery, Coginitive behavioral og TAU) resultater repræsenteret i hver deres række. Jeg vil senere i bloggen tale og vise forskellen på long og wide-format data (hvor hver effektstørrelse har en række), og hvordan man benytter `pivot_longer()` og `pivot_wider()` fra `tidyr`-pakken til at skifte mellem disse to formater. 
<br />

<br />

Når man indtaster data, kan det være en klar fordel at konstruere treatment/group variabel sådan at treatment gruppen/grupperne kommer indtastet før kontrol gruppen. Hvis dette gøres er det i hvert fald lettere at genbruge mine koder fra tidligere projekter, da det altid er måden jeg gør det på. Derudover benytter jeg aldrig store start bogstaver, når jeg laver variabelnavne. Det er kun værdierne inden for en variabel, jeg kan finde på at give store bogstaver.
```{r}

Fisher1996 <- tibble::tibble(
  
  outcome = rep(c("Alcohol use", "Drug use", "Social", "Psych func"), each = 6), 
  
  setting = rep(c("Inpatient", "Outpatient"), each = 3, 4),
  
  treatment = rep(c("Disease", "Cognitive", "TAU"), 8),
  
  N = rep(c(6,6,7), 8), 
  
  m_pre = c(
    
    # Alle værider som er indtaster i de andre variable har samme rækkefølge som denne variabel
    # Det er altid en god ide at skrive en vha. # som viser hvilket outcome der indtastes
    
    .469, .441, .349, # Alcohol use - inpatient
    .725, .598, .682, # Alcohol use - outpatient
    
    .107, .116, .117, # Drug use - inpatient 
    .219, .200, .322, # Drug use - outpatient
    
    .342, .419, .450, # Social and family relations - inpatient
    .683, .584, .571, # Social and family relations - outpatient
    
    .393, .498, .605, # Psychological functioning - inpatient  
    .464, .476, .487  # Psychological functioning - outpatient
    
    
  ),
  
  sd_pre = c(
    .12, .13, .22,
    .11, .16, .17,
    
    .09, .10, .12,
    .11, .12, .05,
    
    .21, .12, .24,
    .04, .05, .09,
    
    .17, .13, .15,
    .14, .12, .16
    
  ),
  
  m_post = c(
    .070, .018, .141,
    .521, .152, .492,
    
    .001, .008, .087,
    .167, .044, .216,
    
    .083, .103, .489,
    .641, .233, .514,
    
    .319, .442, .601,
    .432, .232, .472
    
  ),
  
  sd_post = c(
    .11, .05, .21,
    .11, .15, .27,
    
    .01, .02, .12,
    .10, .05, .15,
    
    .10, .10, .18,
    .06, .16, .12,
    
    .14, .16, .18, 
    .18, .07, .18
    
    
  ),
  
  m_diff = c(
    .399, .423, .208,
    .204, .446, .190,
    
    .106, .108, .030,
    .052, .196, .106,
    
    .259, .316, -.039,
    .042, .351, .057,
    
    .074, .056, .004, 
    .032, .244, .015
    
  ),
  
  sd_diff = c(
    .02, .09, .04,
    .01, .02, .11,
    
    .09, .09, .02, 
    .02, .08, .11,
    
    .13, .03, .07,
    .03, .12, .04,
    
    .04, .04, .04,
    .05, .06, .03
    
  ),
  
  # Here we test if the mean differences reported in the study are in line
  # with the differences between the reported pre and post means. It seems to
  # be the case that they make a reporting error for the cognitive outpatient 
  # group mean difference on drug use. Write about the error can be on many levels
  mean_diff_test = m_pre - m_post,
  
); Fisher1996

```


## Typiske fejl, når man indtaster data
Når man benytter `rep()` til at skabe en variabel i et datasæt, er en af de mest typiske fejl man laver, at man genererer variabler, som ikke har lige mange værdier. Hvis dette er tilfældet, får man en fejlmelding a la den nedenfor.

```{r, eval=FALSE}

tibble(
  var1 = rep(1:2, 2),
  var2 = rep(c("A", "B"), 3)
)

#Error in `tibble()`:
#! Tibble columns must have compatible sizes.
#• Size 4: Existing data.
#• Size 6: Column at position 2.
#ℹ Only values of size one are recycled.
#Run `rlang::last_trace()` to see where the error occurred.
```


# Effektstørrelsesudregning med kompleks data
Når man får fingrene i så komplekst afrapporteret data som den fra Tabel 1, opstår der en række spørgsmål ift. hvilken typer af effektstørrelser, som vil være de bedste at beregne, idet man kan vælge en række forskellige effektstørrelsesindekser i dette tilfælde. Jeg vil her gennemgå de tre mest kendte typer af effektstørrelser som man vil kunne beregne ud fra denne data, og vise, hvordan man kan beregne pre-posttest korrelationer $\rho_{prepost}$, når data er afrapporteret som i Tabel 1. 

## Cohens' $d$
Den vel nok mest kendte effektstørrelse, som man vil møde i litteraturen er den som kaldes Cohens' $d$. Denne effektstørrelse beregnes således

\begin{equation}
  \tag{1}
   d = \left(\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\right)
\end{equation}

hvor $M^T_{post}$ og $M^C_{post}$ er posttestmål for hhv. treatment og kontrolgruppen, mes $SD_{pool}$ beregnes via

\begin{equation}
  \tag{2}
   SD_{pool}  = \sqrt{\frac{(n^T_{post} -1)\times(SD^T_{post})^2 + (n^C_{post} -1)\times(SD^C_{post})^2}{n^T + n^C - 2}}
\end{equation}

$n^T$ og $n^C$ samt $SD^T_{post}$ og $SD^C_{post}$ er samplestørrelsen og standardafvigelsen på posttest niveau for hhv. treatment og kontrolgruppen. Sampling variansen for Cohens' $d$ er givet ved

\begin{equation}
  \tag{3}
   Var_d = \left(\frac{1}{n^T} + \frac{1}{n^C}\right) + \frac{d^2}{2df}
\end{equation}

hvor $df = n^T + n^C$ når der ikke er clusteringproblemer. En meget vigtig viden, som forhåbentlig kan gøre det lettere at forstå, hvorfor vi senere laver cluster-justeringer og hvordan vi gennemfører publikationsbiastests, er, at forstå, at det første led i formel (2), dvs. $\left(\frac{1}{n^T} + \frac{1}{n^C}\right)$, indfanger sampling variationen for tælleren i formel (1), dvs. $M^T_{post} - M^C_{post}$, mens andet led i formel (2), dvs. $\frac{d^2}{2df}$ indfanger sampling variansen for nævner i formel (1), dvs. $SD_{pool}$. Det er første led, som skaber det store bias, hvis et studie ikke har håndtere klustering korrekt. Så når vi senere kluster bias korrigerer effekterne fra dette studie, vil i se, at led et få gange en kluster faktor på sig, som ofte vil gøre dette led substantielt større. En anden vigtig del ift. formel (3) er at forstå, at andet leddet i formel (3) (dvs. leddet til højre for $+$-tegnet), og senere formel (8), skaber en falsk korrelation mellem $d$ og $Var_d$ (se Pustejovsky & Rodgers, [(2019)](https://doi.org/10.1002/jrsm.1332), fordi $d$ benyttes til at beregne dette led. Når vi estimerer publikationsbias test fjerner vi derfor dette led, så kan vi ikke risikerer fejlagtigt at konkludere at små studier oftere afrapporterer større effekter, som blot skyldes et beregningsartifakt. Variansleddet vi benytter i publikationsbiastest ser derfor således ud;  


\begin{equation}
  \tag{4}
   W_d = \left(\frac{1}{n^T} + \frac{1}{n^C}\right)
\end{equation}

### Beregning af standardafvigelse baseret på alle grupper i fleregruppe studier

Når man har med fleregruppe studier (dvs. multi-arm trials), som Fisher studiet her, kan man argumentere for, at en bedre beregning af
den poolede standardafvigelse (SD) ville bero på en SD, som er baseret på alle målte SDs på tværs af alle grupperne i forsøget. Dermed vil den poolede SD holdes konstant på af de forskellige effekter. Det er normalt ikke noget vi benytter i vores reviews, men jeg viser her formlen og koderne til at beregne denne, hvis man skulle få brug for den. Hvis man vil bruge denne tilgang, så beregnes den samlede $SD_{pool, all}$ således

\begin{equation}
  \tag{5}
   SD_{pool, all} = \sqrt{\frac{1}{N-T-1}\sum^{T}_{t=0}(n^t-1)(SD^t_{post})^2}
\end{equation}

hvor $N = \sum^{T}_{t=0}n^t$ for treatmentgrupperne $t=0,...,T$ med $t=0$ svarende til kontrolgruppen ($C$).

```{r}

SD_all_arms <- 
  Fisher1996 |> 
  dplyr::summarise(
    # Her beregner jeg formel (5)
    SD_all_arm = sqrt( (1/(sum(N)-3-1)) * sum((N-1)*sd_post^2) ),
    .by = c(outcome, setting)
  ) |> 
  slice(rep(1:8, 2)) |> 
  arrange(outcome, setting) |> 
  mutate(
    treatment = rep(c("Disease", "Cognitive"), 8)
  ) |> 
  relocate(treatment, .after = setting)
  

```

Det objekt kan senere bindes sammen med vores effektstørrelsesdata. 

## Hedges' $g$
En anden meget kendte effektstørrelser er den såkaldte Hedges' $g$. Forskellen med Cohens' $d$ og Hedges' $g$ er, at Hedges $g$ korrigerer en overestimeringfejl i Cohens' $d$. Det vil konkret sige at Cohens' $d$ bliver for stor ift. den sande bagvedliggende effekt som forsøges estimeres, når sample størrelsen er lille, dvs. når $n^t<20$. Derfor ganges en korrektion faktor $J = 1 - \frac{3}{(4-df-1)}$ på formlel (1). Det ser ud således

\begin{equation}
  \tag{6}
   g = J\left(\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\right)
\end{equation}

Larry Hedges, som har udviklet denne effektstørrelse, har senere fundet, at det ikke er nødvendigt at korrigere variansen for denne effektstørrelse. Det vil sige, at vi kan beregne sampling variansen med formel (2). I vil kunne støde på nogle referencer, som ganger $J^2$ på formel (2), men dette ser som sagt ikke længere ud til at være nødvendigt. 

## Glass' $\Delta$

Den sidste også relativt kendte effektstørrelse er Glass' $\Delta$. Denne effektstørrelse adskiller sig ved, at man kun benytter post-test standardafvigelsen fra kontrolgruppen, $SD^C_{post}$, til at standardisere/skalere effektforskellen i formel (1). Det bygger på antagelsen om, at kontrolgruppen ligner den fulde population mest, da disse ikke har været udsat for en intervention. Den ser således ud

\begin{equation}
  \tag{7}
   \Delta = \left(\frac{M^T_{post} - M^C_{post}}{SD^C_{post}}\right)
\end{equation}

Formel (2) kan også benyttes til at beregne sampling for $\Delta$

## Pretest/baseline adjustede effektstørrelser
Ovenfor har jeg vist en række af de mest kendte og simple effektstørrelsesformler. Fælles for disse er, at de alle sammen 'kun' benytter posttest-effekter til at beregne gennemsnitforskellen mellem treatment og kontrolgruppen, som beror på den antagelse at de raw means er unbiased. Det kan dog være en hård antagelse i mange tilfælde, når vi tillader ikke-randomiserede studier i vores reviews, da means ofte vil være en biased i forskellig grad grundet brug af samples som ikke er trukket via randomisering. Dog kan antagelsen også være hård for means, der kommer fra RCTs, især små RCTer, da samplingfejl selvfølgelig også kan forekomme i den type af studier. En løsning til at formildne dette intern validitetsprogram, er at beregne, de såkaldte difference-in-differences (DID) effektstørrelser (og kaldte pretest-adjusted effect sizes), hvor man kontrollerer baseline forskellene på outcme variablen ud mellem treatment og kontrolgruppen. Vi vil ofte beregne både Hedges' $g$ og DID effektstørrelser, men jeg er ret stor fan af den sidste og vil altid lægge mest vægt på fotolkningen af disse, dels fordi denne effektsttørreslser kan reducere bias og dels fordi den kan estimateres mere præcist (se Hedges et al. [2023](https://doi.org/10.1111/bmsp.12296)).  Formlen for DID effektstørrelsen er givet ved

\begin{equation}
  \tag{8}
   g_{DID} = J \left(\frac{[M^T_{post} - M^T_{pre}] - [M^C_{post} - M^C_{pre}]}{SD_{pool}}\right)
\end{equation}


hvor $M^T_{post}$ og $M^C_{post}$ samt $M^T_{pre}$ og $M^C_{pre}$ er post- og baselinemål for hhv. treatment- og kontrolgruppen, og $SD_{pool}  = \sqrt{\frac{(n^T_{post} -1)\times(SD^T_{post})^2 + (n^C_{post} -1)\times(SD^C_{post})^2}{n^T + n^C - 2}}$, mens $n^T$ og $n^C$ samt $SD^T_{post}$ og $SD^C_{post}$ er samplestørrelsen og standardafvigelsen for hhv. treatment og kontrolgruppen. $J$ i formel (1) er Hedges' sample sample korrektor lige med $1 - \frac{3}{4df-1}$ (nogen trækker 9 fra $df$ i stedet for 1, men det har ingen substantiel betydning). 
<br /> 
<br /> 
Hvis vi antager, at der ikke er klusterproblmer, så er $df = n^T + n^C$. Når der er klusteringproblemer kan $df$ beregnes via Equation  E.21 ([WWC, 2023](https://ies.ed.gov/ncee/WWC/Docs/referenceresources/Final_WWC-HandbookVer5_0-0-508.pdf), s. 171) eller hvis der kun er klustering i en gruppe Equation 7 i Hedges og Citkowicz ([2015](https://doi.org/10.3758/s13428-014-0538-z)). Sampling variansen for $g_{DID}$ er givet ved 

\begin{equation}
  \tag{9}
   Var_{g_{DID}} = \left(\frac{1}{n^T} + \frac{1}{n^C}\right) 2(1-\rho_{prepost})  + \frac{g_{DID}^2}{2df}
\end{equation}


Problemet er dog, at man skal kende pre-posttest korrelationen, $\rho_{prepost}$, for at kunne beregne variansen korrekt. I mange tilfælde vil vi være i stand til at kunne beregne denne (se eksempel nedenfor). Se eksemplvis formlerne fra [Cochranes handbook](https://training.cochrane.org/handbook/current/chapter-06#section-6-5-2-8) eller formel 31 i Wilson ([2016](https://mason.gmu.edu/~dwilsonb/downloads/esformulas.pdf)). Se også denne blog på [VIVECampbell siden](https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html). Alternativt kan $Var_{g_{DID}}$ beregnes korrekt, hvis forfatterne har afrapporteret $t$- eller $F$-værdier fra repeated ANOVA, ANCOVA eller en regressions model, som har inkluderet pretest-outcome som kontrol variabel. Hvis dette er tilfældet, så 

\begin{equation}
  \tag{10}
   Var_{g_{DID}} = \frac{g_{DID}^2}{t^2} + \frac{g_{DID}^2}{2df}
\end{equation}


Bemærk her at $F = t^2$. Se [James Pustejovskys blog](https://www.jepusto.com/alternative-formulas-for-the-smd/) for en yderligere uddybning. Det er igen vigtigt her at notere, at når vi benytter disse typer af effektstørrelser i publikationsbiastests, fjernes igen andet leddet (dvs. leddet på højre side af $+$-tegnet) i formlerne (8) og (9).



### Beregning af pre-posttest korrelation $\rho_{prepost}$
For at kunne beregne sampling variansen for $g_{DID}$ skal vi kende, estimere eller imputere en værdi for korrelationen mellem pretest og postscorene, $\rho_{prepost}$. jeg vil på et senere tidspunkt skrive en blog, hvor jeg vil vise eksempler på alle de måder jeg kender til, hvorpå man kan bakke ud $\rho_{prepost}$. Når resultaterne er afrapportet som i Tabel 1, kan vi faktisk udregne den $\rho_{prepost}$ for hhv. treatment- og kontrolgruppen. Her kan vi benytte formler fra [Cochranes handbook](https://training.cochrane.org/handbook/current/chapter-06#section-6-5-2-8), som for treatmentet gruppen kan beregnes vha

\begin{equation}
  \tag{11}
   \rho^T_{prepost} = \frac{(SD^T_{pre})^2 + (SD^T_{post})^2 - (SD^T_{diff})^2}{2 \times SD^T_{pre} \times SD^T_{post}}
\end{equation}

og for kontrolgruppen

\begin{equation}
  \tag{12}
   \rho^C_{prepost} = \frac{(SD^C_{pre})^2 + (SD^C_{post})^2 - (SD^C_{diff})^2}{2 \times SD^C_{pre} \times SD^C_{post}}
\end{equation}

Disse beregninger kan vi faktisk lave/tilføje direkte i vores datasæt indtastet ovenfor
<br />

```{r}
Fisher1996 <- 
  Fisher1996 |> 
  mutate(
  
  # Regnes som i formler (11) og (12). I kan finde disse i Cochrane handbook (Higgins & Thomas, 2019, p. 166).
  r = (sd_pre^2 + sd_post^2-sd_diff^2)/(2 * sd_pre * sd_post ),
  
  ) 

```

Nu kender vi pre-posttest korrelationen for hhv. treatment- og kontrolgrupperne, men for at kunne beregne $\rho_{prepost}$ skal vi beregne den gennemsnitlige korrelation baseret på korrelationen fra den treatment- og kontrolgruppe, som benyttes til at udregne den givne effektstørrelse. For præcist at kunne beregne denne omregner man korrelationer til Fishers' z-scores via $z_i = 0.5 \times ln\left(\frac{1+\rho^i_{prepost}}{1-\rho^i_{prepost}}\right)$ med varians $v_i = \frac{1}{n-3}$, hvor $n$ er gruppenstørrelsen. Varians bruges som vægt via $w_i = \frac{1}{v_i}$, når Fishers z-score konverteres tilbage til en korrelation-coefficient, således $\rho^i_{prepost}$  med flest observationer/individer får størst vægt. Disse kan beregnes direkte i de råt indtastede data således

```{r}

Fisher1996 <- 
  Fisher1996 |> 
  mutate(
  z = 0.5 * log( (1+r)/(1-r) ),
  v = 1/(N-3),
  w = 1/v
  )

```

Den gennemsnitlige Fishers' z-score på tværs af grupperne kan derefter beregnes således

\begin{equation}
  \tag{13}
   \bar{z_r} = \frac{\sum^g_{i = 1}w_iz_i}{\sum^g_{i = 1}w_i}
\end{equation}

Herefter kan den gennemsnitlige pre-posttest korrelation på tværs af grupper beregnes via

\begin{equation}
  \tag{14}
   \bar\rho_{prepost} = \frac{e^{(2\bar{z_r}})-1}{e^{(2\bar{z_r})}+1}
\end{equation}

Jeg viser, hvordan dette kan beregnes, som det første i nedenstående effektstørrelsesudregninger i næste sektion. 

# Omsætning af formlerne til beregninger i R

Nedenfor vil jeg vise, hvordan I kan omsætte ovenstående formler, dvs. beregne Cohens' $d$, Hedges' $g$ samt difference-in-differences effektstørrelser i R, og senere også hvordan i korrigere disse for klusterfejl. I eksemplet nedenfor fjerner jeg den ene treatment gruppe for at forsimple beregningerne. Jeg vil længere nede vise, hvordan I let kan skabe de samme beregninger på tværs af forskellige treatment-grupper. Når jeg arbejder med effektstørrelsesdata i R, har jeg en række regler jeg arbejder ud fra. Den første er, at jeg altid opkalder det rå effekt-data med efternavnet på førteforfatteren og udgivelsesåret for studiet, således at objektnavnet bliver `AuthorYear`. Objektet som indeholder effektstørrelsesudregningerne kalder jeg altid `AuthorYear_est`. `est` står for '**E**ffect **S**izes standardized with the **T**otal variation'. Lad os springe ud i det. 


```{r}
Fisher1996_es_disease <- 
  Fisher1996 |> 
  # Her fjerner jeg den treatment gruppen "Cognitive" for at kunne beregne effektstørrelser
  # mellem Diasease og kontrol treatment
  dplyr::filter(treatment != "Cognitive") |> 
  dplyr::summarise(
      study = "Fisher1996",
      treatment = treatment[1],
      main_es_method = "diff-in-diffs",
      
      #Her regner vi den gennemsnitlige Fishers z-score som angivet i formel (13)
      mean_z = sum(w*z)/sum(w),
      #Her beregner vi den gennemsnitlige pre-posttest korrelation som angivet i formel (14) 
      ppcor = (exp(2*mean_z)-1)/(exp(2*mean_z)+1),
      # Her dokumneterer jeg, hvor vi har fundet pre-posttest korrelationen 
      ppcor_calc_method = "Calculated from study results",
      
      # Her laver vi variabler, som viser sample størrelser opdelt på treatment- og kontrolgrupperne
      N_t = N[1],
      N_c = N[2],
      # Her laver vi en variabler med den totale samplestørrelse
      N_tot = sum(N),
      
      # Her laver vi variablen med antal frihedsgrader, som benyttes hhv. til 
      # beregne andet led i variansformlerne (3) og (9) samt til at skabe J faktoren
      # der bruges til beregne Hedges' g
      df_ind = N_tot,
      
      # Her beregnes en pooled standardafvigelse som vist i formel (2)
      sd_pool = sqrt(sum((N - 1) * sd_post^2) / df_ind),
      
      # Beregning af tælleren i formler (1), (6) og (7) 
      # Jeg vender her skalen om, da et fald i scoren på de givne skalaer indikerer en positiv fremgang
      m_diff_post = (m_post[1]-m_post[2])*-1,
      
      # Beregning af Cohens' d fra formel (1)
      d_post = m_diff_post/sd_pool,
      # variansudregning fra formel (3)
      vd_post = sum(1/N) + d_post^2/(2*df_ind),
      # Her beregnes det variansled, som er angivet i formel (4) og benyttes til 
      # publikationsbias testning
      Wd_post = sum(1/N),
      
      # Beregnig af Hedges' g fra formel (6)
      J = 1 - 3/(4*df_ind-1),
      g_post = J * d_post,
      vg_post = vd_post,
      Wg_post = sum(1/N),
      
      # Beregnig af Glass' delta fra formel (7). Vi bruger aldrig denne, så den 
      # er kun med her for eksemplets skyld
      sd_control = sd_post[2],
      delta_post = m_diff_post/sd_control,
      
      # Difference-in-differences (DID) effektstørrelsen
      # Her beregner jeg den raw pre-posteffekt forskelle for hhv. treatment og
      # gruppen.
      diff_t = (m_post[1] - m_pre[1])*-1,
      diff_c = (m_post[2] - m_pre[2])*-1,
      
      # Her skaber jeg så tælleren fra formel (8)
      DD = (diff_t - diff_c),
      
      # Her bergener jeg hele formel (8)
      d_DID = (diff_t - diff_c) / sd_pool,
      # Her beregner jeg formel (9)
      vd_DID = sum(1/N) * (2*(1-ppcor)) + d_DID^2/(2*df_ind),
      # Hvis man vil beregne standardfejlen istedet tager man blot kvadratroden af variansen
      sed_DID = sqrt(vd_DID),
      # Her skabes den variabel som benyttes når vi skal gennemføre publikationsbias tests
      Wd_DID = sum(1/N) * (2*(1-ppcor)),
      
      # Her gøres det samme bare hvor vi indregner sample sample bias korrektoreren J
      g_DID = J * d_DID,
      vg_DID = sum(1/N) * (2*(1-ppcor)) + g_DID^2/(2*df_ind),
      Wg_DID = Wd_DID,
     
     # Effektstørrelserne skal beregne indenfor hver setting og outcome, 
     # Derfor grupperer jeg beregninger således
     .by = c(setting, outcome)
      
     
    ) |> 
    relocate(study)

Fisher1996_es_disease
```


## Funktion til effektstørrelsesberegning med mere end to treatment- og/eller kontrolgrupper
Ovenfor har jeg vist, hvordan man kan beregne effektstørrelser, når der er en treatment gruppe. Nu vil jeg vise, hvordan man brugen funktionskabning til at lave de samme beregninger for flere treatmentgrupper, der skal sammenlignes med den samme kontrolgruppe, som i dette tilfælde vi beskæftiger os med. 
```{r}
treat_label_fisher <- unique(Fisher1996$treatment)[1:2]

fisher_func <- function(label){
  
  Fisher_effects <- 
  Fisher1996 |> 
  # Her fjerner jeg den treatment gruppen "Cognitive" for at kunne beregne effektstørrelser
  # mellem Diasease og kontrol treatment
  dplyr::filter(treatment != label) |> 
  dplyr::summarise(
      study = "Fisher1996",
      treatment = treatment[1],
      main_es_method = "diff-in-diffs",
      
      #Her regner vi den gennemsnitlige Fishers z-score som angivet i formel (12)
      mean_z = sum(w*z)/sum(w),
      #Her beregner vi den gennemsnitlige pre-posttest korrelation som angivet i formel (13) 
      ppcor = (exp(2*mean_z)-1)/(exp(2*mean_z)+1),
      # Her dokumneterer jeg, hvor vi har fundet pre-posttest korrelationen 
      ppcor_calc_method = "Calculated from study results",
      
      # Her laver vi variabler, som viser sample størrelser opdelt på treatment- og kontrolgrupperne
      N_t = N[1],
      N_c = N[2],
      # Her laver vi en variabler med den totale samplestørrelse
      N_tot = sum(N),
      
      # Her laver vi variablen med antal frihedsgrader, som benyttes hhv. til 
      # beregne andet led i variansformlerne (3) og (9) samt til at skabe J faktoren
      # der bruges til beregne Hedges' g
      df_ind = N_tot,
      
      # Her beregnes en pooled standardafvigelse som vist i formel (2)
      sd_pool = sqrt(sum((N - 1) * sd_post^2) / df_ind),
      
      # Beregning af tælleren i formler (1), (6) og (7) 
      # Jeg vender her skalen om, da et fald i scoren på de givne skalaer indikerer en positiv fremgang
      m_diff_post = (m_post[1]-m_post[2])*-1,
      
      # Beregning af Cohens' d fra formel (1)
      d_post = m_diff_post/sd_pool,
      # variansudregning fra formel (3)
      vd_post = sum(1/N) + d_post^2/(2*df_ind),
      # Her beregnes det variansled, som er angivet i formel (4) og benyttes til 
      # publikationsbias testning
      Wd_post = sum(1/N),
      
      # Beregnig af Hedges' g fra formel (6)
      J = 1 - 3/(4*df_ind-1),
      g_post = J * d_post,
      vg_post = vd_post,
      Wg_post = sum(1/N),
      
      # Beregnig af Glass' delta fra formel (7). Vi bruger aldrig denne, så den 
      # er kun med her for eksemplets skyld
      sd_control = sd_post[2],
      delta_post = m_diff_post/sd_control,
      
      # Difference-in-differences (DID) effektstørrelsen
      # Her beregner jeg den raw pre-posteffekt forskelle for hhv. treatment og
      # gruppen.
      diff_t = (m_post[1] - m_pre[1])*-1,
      diff_c = (m_post[2] - m_pre[2])*-1,
      
      # Her skaber jeg så tælleren fra formel (8)
      DD = (diff_t - diff_c),
      
      # Her bergener jeg hele formel (8)
      d_DID = (diff_t - diff_c) / sd_pool,
      # Her beregner jeg formel (9)
      vd_DID = sum(1/N) * (2*(1-ppcor)) + d_DID^2/(2*df_ind),
      # Hvis man vil beregne standardfejlen istedet tager man blot kvadratroden af variansen
      sed_DID = sqrt(vd_DID),
      # Her skabes den variabel som benyttes når vi skal gennemføre publikationsbias tests
      Wd_DID = sum(1/N) * (2*(1-ppcor)),
      
      # Her gøres det samme bare hvor vi indregner sample sample bias korrektoreren J
      g_DID = J * d_DID,
      vg_DID = sum(1/N) * (2*(1-ppcor)) + g_DID^2/(2*df_ind),
      Wg_DID = Wd_DID,
     
     # Effektstørrelserne skal beregne indenfor hver setting og outcome, 
     # Derfor grupperer jeg beregninger således
     .by = c(setting, outcome)
      
     
    ) |> 
    relocate(study)

  # Her omformer jeg Fisher1996 til et wide format, så det har samme længde, som 
  # effect størrelsesdatasæt ovenfor
  Fisher_raw_dat_wide <- 
   Fisher1996 |> 
   filter(treatment %in% c(label, "TAU")) |> 
   mutate(
     treatment = if_else(treatment == label, "t", "c")
   ) |> 
   pivot_wider(
     names_from = treatment, 
     values_from = N:w
   ) |> 
  mutate(
    group_t = label,
    group_c = "TAU"  
  ) |> 
  relocate(group_t:group_c, .after = setting)

 # Her binder jeg de raw mål sammen med effectstørrelsesudregningerne
 left_join(Fisher_raw_dat_wide, Fisher_effects, by = join_by(outcome, setting, N_t, N_c))
  
  
}

# Her bruger jeg funktionen til at beregne effekter for begge treatments holdt op imod den
# samme kontrol gruppe
Fisher1996_es <- 
  purrr::map(treat_label_fisher, ~ fisher_func(.x)) |> 
  list_rbind() |> 
  mutate(
    study = "Fisher (1996)"
  ) |> 
  relocate(study) |> 
  arrange(setting, outcome) |> 
  relocate(setting, .before = outcome)

Fisher1996_es
```


## Cluster bias korrektion når der kun er klustering i en gruppe 

<br />
\begin{equation}
  \tag{15}
   gt_{DID} = \omega\left(\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\right)\gamma
\end{equation}
<br />

hvor $\omega = 1 - 3/(4-df_h-1)$, hvor $df_h$ er de klusterjusterede frihedsgrader, som beregnes for således når der kun er klustering i en gruppe

<br />
\begin{equation}
  \tag{16}
   h = \dfrac{[(N-2)-2(n-1)\rho]^2}{(N-2)(1-\rho)^2 + n(N-2n)\rho^2 + 2(N-2n)\rho(1-\rho)}
\end{equation}
<br />

i formel 14 er $\gamma = \sqrt{1-\frac{(N^c +n-2)\rho_{ICC}}{}}$


```{r}

# Imputerede ICC-værdier
icc_005 <- 0.05 # Bruges til sensitivitetsanalyse
icc_01 <- 0.1
icc_02 <- 0.2 # Bruges til sensitivitetsanalyse

Fisher1996_est <- 
  Fisher1996_es |> 
  rowwise() |> 
  # klusterkorrigering
  mutate(
    
    # Gruppestørrelsen kan ikke findes i Fisher 1996, så her imputerer vi blot den 
    # gennemsnitlige gruppestørrelse for eksemplet skyld
    n_group = 5,
    # Laver variabel med den imputere ICC værdi
    icc = icc_01,
    # Laver variabel som dokumenterer hvor vi fandt ICC-værdieen
    icc_type = "Imputed",
    
    gamma_sqrt = VIVECampbell::gamma_1armcluster(
      N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc, sqrt = TRUE
    ), 
    gamma_sqrt_test = sqrt(1 - (N_c + n_group-2)*icc/(N_tot-2)), 
    
    h = df_h_1armcluster(N_total = N_tot, ICC = icc, N_grp = N_t, avg_grp_size = n_group),
    omega = 1 - 3/(4*h-1),
      
    gt_post = omega * d_post * gamma_sqrt,
    VIVECampbell::vgt_smd_1armcluster(
      N_cl_grp = N_t, 
      N_ind_grp = N_c, 
      avg_grp_size = n_group,
      ICC = icc, 
      g = gt_post, 
      model = "posttest",
      add_name_to_vars = "_post",
      vars = c(vgt_post, Wgt_post)
    ),
    
    gt_DID = omega * d_DID * gamma_sqrt,
    VIVECampbell::vgt_smd_1armcluster(
      N_cl_grp = N_t, 
      N_ind_grp = N_c, 
      avg_grp_size = n_group,
      ICC = icc, 
      g = gt_DID, 
      model = "DiD",
      prepost_cor = ppcor,
      add_name_to_vars = "_DID",
      vars = -var_term1_DID
    ),
    
    # Disse variabler skabes til at lave sensitivitetsanalyser
    
    # Her antager vi at ICC = 0.05
    gamma_sqrt_005 = VIVECampbell::gamma_1armcluster(
      N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc_005, sqrt = TRUE
    ), 
    h_005 = df_h_1armcluster(N_total = N_tot, ICC = icc_005, N_grp = N_t, avg_grp_size = n_group),
    omega_005 = 1 - 3/(4*h_005-1),
    
    gt_DID_005 = omega_005 * d_DID * gamma_sqrt_005,
    VIVECampbell::vgt_smd_1armcluster(
      N_cl_grp = N_t, 
      N_ind_grp = N_c, 
      avg_grp_size = n_group,
      ICC = icc_005, # Husk at ændre denne
      g = gt_DID_005, #Husk at ændre denne
      model = "DiD",
      prepost_cor = ppcor,
      add_name_to_vars = "_DID_005",
      vars = c(vgt_DID_005, Wgt_DID_005)
    ),
    
    # Her antager vi at ICC = 0.2
    gamma_sqrt_02 = VIVECampbell::gamma_1armcluster(
      N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc_02, sqrt = TRUE
    ), 
    h_02 = df_h_1armcluster(N_total = N_tot, ICC = icc_02, N_grp = N_t, avg_grp_size = n_group),
    omega_02 = 1 - 3/(4*h_02-1),
    
    gt_DID_02 = omega_02 * d_DID * gamma_sqrt_02,
    VIVECampbell::vgt_smd_1armcluster(
      N_cl_grp = N_t, 
      N_ind_grp = N_c, 
      avg_grp_size = n_group,
      ICC = icc_02, 
      g = gt_DID_02, 
      model = "DiD",
      prepost_cor = ppcor,
      add_name_to_vars = "_DID_02",
      vars = c(vgt_DID_02, Wgt_DID_02)
    ),
    
    vary_id = paste(setting, outcome, treatment, sep = "/")
  ) |> 
  ungroup()

Fisher1996_est

```

## Konstruktion af varians-covarians matrix når man har mere end en treatment (og/eller kontrol) gruppe

```{r}

V_dat_test <- 
  Fisher1996_es |> 
  #dplyr::filter(setting == "Inpatient") |> 
  metafor::escalc(measure="SMD", yi = g_DID, vi = vg_DID, data = _) |> 
  mutate(esid = 1:n())

V_vcalc <- 
  metafor::vcalc(
    data = V_dat_test,
    vi = vi, 
    cluster = study,
    subgroup = setting,
    obs = outcome, 
    grp1 = group_t,
    w1 = N_t, 
    grp2 = group_c,
    w2 = N_c,
    rho = 0.7, 
    sparse = TRUE
  )

V_vcalc |> as.matrix() |> as.data.frame()
V_vcalc |> cov2cor()
  
# Assuming constant correlation

V_vcalc_constant <- 
  metafor::vcalc(
    data = V_dat_test,
    vi = vi, 
    cluster = study,
    obs = esid, 
    rho = 0.7, 
    sparse = TRUE
  )

V_vcalc_constant
V_vcalc_constant |> cov2cor()



```


## Long and wide format data

Begge formater har hver deres ulemper. Man skal skrive mindre kode, når man beregner effektstørrelser med long format data, men man har dermed også et datasæt som i antal af rækker ikke passer sammen med den endelige effektstørrelsesdata. Omvendt, kræver det længere koder at kode wide format data, men her får man tilgengæld også et datasæt som passer i antal med dette endelige effektstørrelses datasæt. På mange af vores andre review indtastes den raw data (som den fra Tabel 1) direkte i excel i stedet for i R. Det kan igen måde have fordele og ulemper. Ved at indtaste det studie for studie i R, bliver det noget tydeligere for læsere, hvor man præcist har udtrykket data, men det kræver også at man skriver langt, langt flere koder, som på mange måder kan være meget tidskrævende. Igen det er meget en smagssag. 

```{r, eval=FALSE}

pivot_wider(
  Fisher1996,
  values_from = m_pre:v,
  names_from = treatment
  )

```




# Visualize effect size data 

```{r, fig.height=5.5, fig.width=8, eval = FALSE}

Fisher1996_est |> 
  tidyr::pivot_longer(
    cols = -c(study:diff_c, J),
    names_to = c('.value', 'Category'), 
    names_sep = '_'
  ) |> 
  mutate(
    CI_L = es - se * qnorm(.975),
    CI_U = es + se * qnorm(.975)
  ) |> 
  filter(treatment == "Cognitive") |> 
  ggplot(aes(x = es, y = Category, xmin = CI_L, xmax = CI_U,
        color = Category)) + 
  geom_pointrange(position = position_dodge2(width = 0.5, padding = 0.5)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black", alpha = 0.5) +
  facet_grid(setting~outcome, scales = "free") +
  theme_bw() +
  theme(legend.position = "bottom") +
  ylab("Effect size type")
  

```


# References 
